\documentclass[12pt,dvipsnames]{article}
\setcounter{section}{0}

\usepackage{amsmath,amsthm,amssymb,amsbsy}
\usepackage[spanish,es-tabla]{babel}
\decimalpoint
\usepackage{braket}
\usepackage{color}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage[T1]{fontenc}
\usepackage[margin=1.5cm]{geometry} 
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{lmodern}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{pgfplots}
\usepackage{soul}
\usepackage{tabularx}
\usepackage{tcolorbox}
\tcbuselibrary{listings,breakable}
\usepackage{tikz}
\usetikzlibrary{babel}
\usepackage{url}
\usepackage{wrapfig}
\usepackage{xcolor}
\allowdisplaybreaks

\setlength{\parindent}{1em}
\setlength{\parskip}{1em}

\definecolor{NARANJA}{rgb}{1,0.467,0}
\definecolor{VERDE}{rgb}{0.31,1,0}
\definecolor{AZUL}{rgb}{0,0.53,1}
\definecolor{ROJO}{rgb}{1,0,0}

\hypersetup{
    colorlinks=true,
    linkcolor=ROJO,
    filecolor=magenta,      
    urlcolor=AZUL,
}
 
\pgfplotsset{compat=1.15}
 
\renewcommand{\figurename}{Figura}

\newcommand{\anim}[2]{\textcolor{red}{\textbf{\hl{#1}}}\footnote{#2}}

\renewcommand{\indexname}{Índice}
\renewcommand{\appendixname}{Apéndice}
\renewcommand{\contentsname}{Contenidos}
\renewcommand{\proofname}{Dem.}
\renewcommand{\tablename}{Tabla.}
\renewcommand\qedsymbol{$\blacksquare$}
\newtheorem{teo}{Teorema}[section]
\newtheorem{cor}{Corolario}[section]
\newtheorem{lem}{Lema}[section]
\newtheorem{defi}{Definición}[section]
\newtheorem{obs}{Observación}[section]
\newtheorem{prop}{Propiedades.}[section]
\newtheorem{ejem}{\textbf{\textit{$\circ \ \text{Ejemplo}$}}}[section]
\newtheorem{axi}{Axioma}[section]

\numberwithin{equation}{section}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%cajas

\newtcolorbox{post}{colback=white,colframe=red!50!black,
	colbacktitle=red!75!black, title= Postulado.}

\newtcolorbox{enu}{colframe=white!85!black, colback=white, leftrule = 10mm, sharp corners, breakable}

\newtcolorbox{solu}{colframe=black, colback=white, leftrule = 1mm, rightrule = -1mm,toprule = -1mm, bottomrule=-1mm, sharp corners, breakable}

\newtcolorbox{corre}{colframe=red, colback=white, leftrule = 1mm, rightrule = -1mm,toprule = -1mm, bottomrule=-1mm, sharp corners, breakable}

\newtcolorbox{enun}{colframe=gray, colback=white!90!black, leftrule = 1mm, rightrule = 1mm, toprule = -1mm, bottomrule=-1mm, sharp corners, breakable}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%cajas

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%demarcado de soluciones

%New colors defined below
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

%Code listing style named "mystyle"
\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

%"mystyle" code listing set
\lstset{style=mystyle}

\newenvironment{sol}{\begin{figure}[H]
		\begin{tikzpicture}
		\filldraw[black] (0,0) circle (3pt);
		\draw[line width = 0.5pt] (0,0) -- (4,0) node[above right]{\textbf{Solución:}};
		\end{tikzpicture}
\end{figure}}{\begin{figure}[H]
		\begin{flushright}
			\begin{tikzpicture}
			\draw[line width = 0.5pt] (0,0)-- (4,0);
			\filldraw (4,0) circle (3pt);
			\end{tikzpicture}
\end{flushright}\end{figure}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%demarcado de soluciones
 
\begin{document}

\title{Norma inducida y bases ortonormales}
\date{}
\maketitle
%\tableofcontents

\begin{obs}
    Las ideas principales a presentar en este video son:

    \begin{enumerate}[label=(\roman*)]
        \item La norma es una operación que, de estar presente en un espacio vectorial, nos da una noción de \emph{magnitud} de un vector, y nos permite hacer comparaciones entre vectores en este sentido. Los vectores con norma uno son llamados \emph{normales} o \emph{unitarios} y todo vector no nulo puede ser reescalado de tal forma que el vector resultante sea normal.

        \item Por definición, un producto escalar en un espacio vectorial induce una norma en ese espacio. Aunque no todas las normas provienen de un producto escalar, en esta serie de videos nos enfocaremos en este tipo de normas. 

        \item La proyección vectorial de un vector arbitrario sobre un vector no nulo puede ser reescrita considerando la norma inducida. Una base en la que todos los vectores son normales y ortogonales entre sí se conoce como una base ortonormal.

        \item Si un espacio vectorial con producto escalar tiene dimensión finita y existe una base ortonormal, entonces el problema de encontrar los coeficientes necesarios para expresar a un vector arbitrario como combinación lineal de esta base tiene una solución extremadamente simple, en donde cada coeficiente se calcula a través de un producto escalar.
    \end{enumerate}
\end{obs}

\begin{obs}
Considerando que la serie está enfocada en abordar la descomposición espectral de operadores lineales, creo que \textbf{no} es necesario incluir en ella una discusión sobre métrica ni normas distintas de aquellas inducidas por un producto escalar positivo definido; sin embargo, sería bueno buscar referencias para estos temas y ponerlas en la descripción.
\end{obs}

%%%%%%%%%%%%%%%%%%%%%%%%%% PRIMERA ESCENA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Introducción de la norma}

\subsection{Necesidad de caracterizar las magnitudes de vectores}

Una de las principales aplicaciones de los vectores es en el modelado de fuerzas físicas y, a veces, es útil pensar en vectores como fuerzas, pues de esta forma algunas de sus propiedades parecen más intuitivas. Por ejemplo, supongamos por un momento que podemos colocar una caja sobre una superficie cuya fricción no depende de la dirección en que se desplacen los objetos sobre ella. Imaginemos primero que empujamos la caja hacia el frente con una fuerza, que llamaremos $\vec{u}$, y luego hacia un lado con una fuerza mayor, que llamaremos $\vec{v}$. Ahora imaginemos que desde el mismo punto de partida empujamos nuestra caja hacia el mismo lado con la misma fuerza $\vec{v}$ antes de empujarla hacia el frente con fuerza $\vec{u}$. Dadas nuestras hipótesis, al empujar la caja en las mismas direcciones y con las mismas fuerzas en cada dirección obtenemos en el mismo desplazamiento neto, sin importar el orden de los empujes. La Ley del Paralelogramo no es más que una generalización de lo que hemos observado en este experimento mental, en la que las fuerzas pueden tener la dirección que sea, además de poder ser arbitrariamente grandes o pequeñas. Luego, el axioma de conmutatividad de la suma vectorial es simplemente una \emph{abstracción} de esta propiedad a cualquier espacio vectorial.

Dado que un aumento o disminución de fuerza implica un respectivo aumento o disminución de desplazamiento, y vice versa, visualmente resulta natural asociar la longitud de la flecha que representa a un vector con la \emph{magnitud} de la fuerza que está representando dicho vector. Más generalmente, podemos pensar que los vectores mismos tienen una magnitud que, intuitivamente, nos dice qué tan cerca o lejos están del vector nulo del espacio en comparación con otros vectores, sin tomar en cuenta hacia dónde apuntan. En otras aplicaciones de los vectores, las magnitudes de estos se pueden interpretar de otras formas pero, para poder hacer uso de todas estas interpretaciones y aprovechar la intuición que nos brindan, necesitamos caracterizar las magnitudes de los vectores de un espacio vectorial de alguna forma.

\subsection{Definición de norma a partir de observaciones geométricas}

Por definición, \emph{todos} los espacios vectoriales deben tener una operación llamada \emph{suma} o \emph{adición vectorial} y otra llamada \emph{multiplicación de un vector por un escalar} o, simplemente, \emph{reescalamiento}\footnote{Podríamos aprovechar la mención de ambas operaciones para implícitamente introducir su interpretación geométrica en el plano real y complejo, siguiendo las notas del curso.}. Por ello, decimos que estas son las operaciones \emph{esenciales} de los espacios vectoriales. Sin embargo, puede que un espacio vectorial tenga, además, \emph{otras} operaciones, que introduzcan \emph{nuevas} nociones en el espacio. Un ejemplo es la operación de producto escalar, la cual introduce las nociones de ortogonalidad y proyección vectorial, como vimos en el video anterior. La caracterización de las magnitudes de los vectores en un espacio vectorial se logra introduciendo otra operación llamada \emph{norma}, que a cada vector del espacio le asigna una cantidad específica para representar el valor de su magnitud. 
\begin{align*}
     & & &\quad \text{Norma}& \\
     & & &||\cdot||:V\to &
\end{align*}
Si volvemos a considerar vectores representados geométricamente como flechas y a asociar las longitudes de las flechas con las magnitudes de los vectores correspondientes, entonces la norma puede definirse mediante sencillas observaciones geométricas. Por ejemplo, como no existen flechas con ``longitud negativa'', la cantidad asignada por la norma a cada vector será un número real no negativo. Además, si sumamos un vector consigo mismo \textemdash o, equivalentemente, si reescalamos a un vector por $2$\textemdash, la magnitud del vector resultante es el doble que la del vector original. Lo mismo ocurre si, en vez de reescalar por $2$, reescalamos por $-2$ pues, aunque el vector invierta el sentido en el cual apunta, su magnitud nuevamente es el doble de la original. Más generalmente, si multiplicamos a un vector por un escalar arbitrario, la magnitud del vector resultante es igual a la magnitud del vector original por el \emph{valor absoluto} de ese escalar \textemdash incluso cuando éste es un número complejo\footnote{Escribir ``*Ver Pregunta 2.? al final del video.'' y cambiar $K$ momentáneamente por $\mathbb{C}$.}. Esto nos da la primera propiedad de la norma, conocida como \emph{escalabilidad absoluta}. %La primera es que el vector nulo del espacio tiene longitud cero, y se distingue por ser el \emph{único} vector con esta propiedad. Por lo tanto, la norma de un vector arbitrario del espacio es cero si, y sólo si, dicho vector es igual al vector nulo del espacio. Esta propiedad de la norma se conoce como \emph{distinción del vector nulo}.
\begin{align*}
     &\quad \quad \quad \quad \quad \text{Norma}& \\
     &\quad \quad \quad ||\cdot||:V\to \mathbb{R}_{\ge0}& \\
     \\
     \forall \ \vec{u},\vec{v}\in V, \ \forall \ a\in K, \\
    \\
    ||a\vec{u}|| = |a| \ ||\vec{u}|| &&\text{Escalabilidad \emph{absoluta}} \\
\end{align*}
Notemos que el vector nulo del espacio tiene magnitud cero; más aún, se distingue por ser el \emph{único} vector con esta propiedad. Por lo tanto, la norma de un vector arbitrario del espacio es cero si, y sólo si, dicho vector es igual al vector nulo. Esta es la segunda propiedad de la norma y se conoce como \emph{distinción del vector nulo}. %Ahora, observemos que si sumamos un vector consigo mismo \textemdash o, equivalentemente, si reescalamos a un vector por $2$\textemdash, la longitud del vector resultante es el doble que la del vector original. Lo mismo ocurre si, en vez de reescalar por $2$, reescalamos por $-2$ pues, aunque el vector invierta el sentido en el cual apunta, su longitud es nuevamente el doble de la original. Más generalmente, la longitud de un vector que ha sido multiplicado por un escalar arbitrario es igual a la longitud del vector original por el \emph{valor absoluto} de ese escalar. Esto nos da la siguiente propiedad de la norma, conocida como \emph{escalabilidad absoluta}.
\begin{align*}
     &\quad \quad \quad \quad \quad \text{Norma}& \\
     &\quad \quad \quad ||\cdot||:V\to \mathbb{R}_{\ge0}& \\
     \\
     \forall \ \vec{u},\vec{v}\in V, \ \forall \ a\in K, \\
    \\
    ||a\vec{u}|| = |a| \ ||\vec{u}|| &&\text{Escalabilidad \emph{absoluta}} \\
     \\
    ||\vec{u}|| = 0 \iff \vec{u} = \vec{0} &&\text{Distinción del vector nulo}
\end{align*}
Por último, observemos que, si consideramos la suma de dos vectores, entonces la magnitud del resultado de la suma debe ser menor o igual a la suma de las magnitudes de los vectores originales. Esto es fácil de ver si consideramos nuevamente la Ley del Paralelogramo y nos enfocamos en cualquiera de los dos triángulos en los que se divide el paralelogramo pues, en estos términos, la observación que hicimos sobre magnitudes de vectores equivale a afirmar que la suma de las longitudes de dos lados de un triángulo siempre debe ser mayor o igual a la del tercer lado. Por ello, esta propiedad de la norma se conoce como la \emph{desigualdad del triángulo}.
\begin{align*}
     &\quad \quad \quad \quad \quad \text{Norma}& \\
     &\quad \quad \quad ||\cdot||:V\to \mathbb{R}_{\ge0}& \\
     \\
     \forall \ \vec{u}, \vec{v}\in V, \ \forall \ a\in K, \\
    \\
    ||a\vec{u}|| = |a| \ ||\vec{u}|| &&\text{Escalabilidad \emph{absoluta}} \\
     \\
    ||\vec{u}|| = 0 \iff \vec{u} = \vec{0} &&\text{Distinción del vector nulo} \\
    \\
    ||\vec{u}+\vec{v}|| \le ||\vec{u}|| + ||\vec{v}|| &&\text{Desigualdad del triángulo}
\end{align*}
Usando las tres propiedades de la norma, se puede demostrar que ésta es una operación positivo definida\footnote{Escribir ``*Ver el Ejercicio 2.1.''.}. A un espacio vectorial con una función que cumpla esta definición se le conoce como un espacio vectorial \emph{normado}.

%%%%%%%%%%%%%%%%%%%%%%%%%% SEGUNDA ESCENA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Definición de vector normal/unitario y conjunto normal}

Más adelante veremos la importancia que tienen los vectores con norma igual a uno, conocidos como vectores \emph{normales}. Por lo pronto, supongamos que en un espacio vectorial normado tenemos un vector no nulo, y lo queremos reescalar de tal forma que se convierta en un vector normal, pero sin cambiar su dirección ni su sentido. Dado que la norma es positivo definida y nuestro vector es distinto del vector nulo, sabemos que su norma es positiva. Observemos que, si reescalamos al vector por el inverso multiplicativo de su norma entonces, por la propiedad de escalabilidad absoluta, se sigue que el vector reescalado es normal.
\[
    \vec{v}\in V, \ \vec{v}\neq \vec{0} \Rightarrow ||\vec{v}||>0.
\] 

\[
\frac{1}{||\vec{v}||} \vec{v}
\] 
\begin{align*}
                \bigg|\bigg|\frac{1}{||\vec{v}||} \vec{v} \bigg|\bigg| &= \bigg| \frac{1}{||\vec{v}||} \bigg| \ ||\vec{v}|| \\ \\
                                                                       &= \frac{1}{||\vec{v}||} ||\vec{v}|| \\ \\
                                                                       &=1.
\end{align*}
\noindent Más aún, como la norma de $\vec{v}$ es positiva, el vector resultante efectivamente apunta en la misma dirección y sentido que el vector original, ¡como queríamos! A los vectores normales, como el que acabamos de obtener, se les suele denotar de la siguiente manera\footnote{Escribir ``vector \emph{normal}'' a la derecha de $\hat{v}$.}: 
\[
    \vec{v}\in V, \ \vec{v}\neq \vec{0} \Rightarrow ||\vec{v}||>0.
\] 

\[
\frac{1}{||\vec{v}||} \vec{v} =: \hat{v}
\] 
\begin{align*}
                \bigg|\bigg|\frac{1}{||\vec{v}||} \vec{v} \bigg|\bigg| &= \bigg| \frac{1}{||\vec{v}||} \bigg| \ ||\vec{v}|| \\ \\
                                                                       &= \frac{1}{||\vec{v}||} ||\vec{v}|| \\ \\
                                                                       &=1.
\end{align*}
Además, a este proceso de reescalar a un vector no nulo por el inverso multiplicativo de su norma para convertirlo en un vector normal se le conoce como \emph{normalización}\footnote{Poner llaves y escribir \emph{normalización} al lado de los renglones correspondientes al proceso, y después borrarlos.}.

Decimos que un conjunto de vectores en un espacio normado es \emph{normal} si todos sus vectores son normales
\[
    \vec{v}\in V, \vec{v}\neq \vec{0} \Rightarrow ||\vec{v}||>0.
\] 

\[
    \frac{1}{||\vec{v}||} \vec{v} =: \hat{v}
\] 

\[
    \text{U}=\{\vec{u}_1,...,\vec{u}_k\}\subseteq V \ \text{es \emph{normal} si } ||\vec{u}_i|| = 1 \text{ para } 1\le i\le k.
\]
Notemos que, en un espacio normado, cualquier conjunto que \emph{no} contenga al vector nulo puede ser convertido en un conjunto normal, simplemente normalizando a cada uno de sus vectores:
\[
    \vec{v}\in V, \vec{v}\neq \vec{0} \Rightarrow ||\vec{v}||>0.
\] 

\[
    \frac{1}{||\vec{v}||} \vec{v} =: \hat{v}
\] 

\[
    \text{U}=\{\vec{u}_1,...,\vec{u}_k\}\subseteq V \ \text{es \emph{normal} si } ||\vec{u}_i|| = 1 \text{ para } 1\le i\le k.
\]

\[
\vec{0}\notin\{\vec{v}_1,...,\vec{v}_k\}\subseteq V \Rightarrow \{\hat{v}_1, ..., \hat{v}_k\}\subseteq V \text{ es un conjunto normal}.
\] 
Volvamos ahora a la ecuación anterior\footnote{Borrar los dos renglones de abajo y los dos puntos de la ecuación restante.}. Observemos que, si la multiplicamos de ambos lados por la norma de $\vec{v}$, obtenemos la siguiente ecuación
\[
    \vec{v}\in V, \vec{v}\neq \vec{0} \Rightarrow ||\vec{v}||>0.
\] 

\[
    \vec{v}= ||\vec{v}|| \hat{v}
\] 
Esta igualdad nos dice que, en un espacio normado, cualquier vector no nulo $\vec{v}$ es igual al vector normal en su misma dirección y sentido reescalado por su norma. De esta forma, en un espacio normado, podemos pensar en los vectores normales como ``unidades'' a partir de las cuales se puede formar a todos los vectores del espacio mediante reescalamientos. Recordando que la norma nos ayuda a comparar magnitudes entre vectores con relación al vector nulo, esto nos dice que los vectores normales sirven como una especie de ``unidad'' en esa escala. Por ende, a los vectores normales también se les conoce como vectores \emph{unitarios}. 

%%%%%%%%%%%%%%%%%%%%%%%%%% TERCERA ESCENA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Norma inducida por un producto escalar} % A partir de cualquier norma se puede definir una \emph{métrica inducida}, lo que nos da una noción de \emph{distancia} entre vectores\footnote{Escribir ``Ver el Ejercicio 2.2.'' como nota al pie.}, aunque esto vas más allá del enfoque de esta serie de videos.

Hasta ahora, en esta serie de videos hemos visto que tanto la norma como el producto escalar son operaciones positivo definidas que distinguen al vector nulo\footnote{Escribir ``Ver el Ejericicio 1.2 del video \emph{Ortogonalización y ortonormalización (Teorema de Gram-Schmidt)} de Animathica.'' como nota al pie.}. Sin embargo, estas no son las únicas relaciones existentes entre estas dos operaciones. Observemos lo siguiente: supongamos que tenemos un espacio vectorial con producto escalar y que definimos una función de la siguiente manera

\begin{align*}
    & &(V,K) \\
    \\
    & &\langle \cdot , \cdot \rangle : V\times V\to K \ \text{es un producto escalar en} \ V\\
    \\
    ||\vec{v}||:=\sqrt{\langle \vec{v} , \vec{v} \rangle} \quad \forall \ \vec{v}\in V
\end{align*}

Entonces, se sigue de las propiedades del producto escalar que nuestra función asigna a cada vector del espacio un número real no negativo y, además, que cumple las siguientes propiedades

\begin{align*}
    & &(V,K) \\
    \\
    & &\langle \cdot , \cdot \rangle : V\times V\to K \ \text{es un producto escalar en} \ V\\
    \\
    ||\vec{v}||:=\sqrt{\langle \vec{v} , \vec{v} \rangle} \quad \forall \ \vec{v}\in V\\
    \\
    ||\cdot||:V\to K\\
    \\
    \forall \ \vec{u}\in V, \ \forall \ a\in K,\\
    \\
    ||a\vec{u}|| = \sqrt{\langle a\vec{u} , a\vec{u} \rangle} = \sqrt{a\overline{a}\langle \vec{u} , \vec{u} \rangle} = \sqrt{a\overline{a}} \sqrt{\langle \vec{u} , \vec{u} \rangle} = |a| \ ||\vec{u}||\\
    \\
    ||\vec{u}|| = 0 \iff \sqrt{\langle \vec{u} , \vec{u} \rangle} = 0 \iff \langle \vec{u} , \vec{u} \rangle = 0 \iff \vec{u} = \vec{0}
\end{align*}

\noindent En otras palabras, nuestra función ya cumple dos de las propiedades de norma. Más aún, se puede demostrar que también cumple la desigualdad del triángulo\footnote{Colocar referencias de desigualdad de Cauchy-Schwarz y la desigualdad del triángulo en la descripción.}, por lo que la función que hemos definido es una norma. En general, siempre que tengamos un espacio vectorial con un producto escalar, ¡podemos definir una norma en ese espacio \emph{a partir} del producto escalar de esta forma! A esto se le conoce como una \emph{norma inducida por un producto escalar}. A pesar de que no todas las normas en un espacio vectorial tengan que ser inducidas por un producto escalar, nos enfocaremos principalmente en este tipo de normas durante el resto de la serie\footnote{Podríamos colocar referencias a normas no inducidas por productos escalares en la descripción del video y añadir una nota al pie que diga ``Ver referencias [N-1], [N-2], etc. en la descripción del video sobre normas no inducidas por productos escalares.''.}.

%%%%%%%%%%%%%%%%%%%%%%%%%% CUARTA ESCENA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Proyecciones vectoriales y vectores unitarios}

\subsection{Proyecciones vectoriales sobre vectores unitarios}

Ahora, volvamos a la expresión de la proyección vectorial de un vector $\vec{u}$ sobre un vector no nulo $\vec{v}$ que vimos al final del video anterior
\[
\vec{u},\vec{v}\in V, \vec{v}\neq \vec{0}
\] 

\[
\frac{\langle \vec{u} , \vec{v} \rangle}{\langle \vec{v} , \vec{v} \rangle} \vec{v} 
\] 
Observemos que, considerando la norma inducida, podemos reescribir esta expresión como sigue:
\begin{align*}
    \vec{u},\vec{v}\in V, \vec{v}&\neq \vec{0} \\ \\
    \frac{\langle \vec{u} , \vec{v} \rangle}{\langle \vec{v} , \vec{v} \rangle} \vec{v} &= \frac{\langle \vec{u} , \vec{v} \rangle}{\big(\sqrt{\langle \vec{v} , \vec{v} \rangle}\big)^2} \vec{v} \\ \\
                                                                                        &= \frac{\langle \vec{u} , \vec{v} \rangle}{||\vec{v}||^2} \vec{v} \\ \\
                                                                                        &= \frac{\langle \vec{u} , \vec{v} \rangle}{||\vec{v}||} \bigg( \frac{1}{||\vec{v}||} \vec{v} \bigg) \\ \\
                                                                                        &= \frac{\langle \vec{u} , \vec{v} \rangle}{||\vec{v}||} \hat{v}
\end{align*}
Es decir, la componente del vector $\vec{u}$ que vive en el subespacio generado por el vector no nulo $\vec{v}$ se obtiene reescalando al vector unitario en la misma dirección y sentido que $\vec{v}$ por el producto escalar de $\vec{u}$ con $\vec{v}$ entre la norma de $\vec{v}$.
\[
    \frac{\langle \vec{u} , \vec{v} \rangle}{\langle \vec{v} , \vec{v} \rangle} \vec{v} = \frac{\langle \vec{u} , \vec{v} \rangle}{||\vec{v}||} \hat{v}
\] 

\subsection{Conjuntos y bases ortonormales}

En un espacio vectorial con producto escalar y norma, decimos que un conjunto es \emph{ortonormal} si es ortogonal y normal. Es decir, un conjunto ortonormal es un conjunto de vectores unitarios que son ortogonales entre sí.
\[
    \text{N}=\{\vec{n}_1,...,\vec{n}_k\}\subseteq V \ \text{es \emph{ortonormal} si} \ \langle \vec{n}_i , \vec{n}_j \rangle = 0 \text{ para } i\neq j \text{ con } 1\le i,j\le k \text{ y } ||\vec{n}_i||=1 \text{ para } 1\le i\le k.
\]
Si consideramos la norma inducida por el producto escalar, entonces el que la norma de un vector sea uno es equivalente a que su producto escalar consigo mismo sea igual a uno
\[
    \text{N}=\{\vec{n}_1,...,\vec{n}_k\}\subseteq V \ \text{es \emph{ortonormal} si} \ \langle \vec{n}_i , \vec{n}_j \rangle = 0 \text{ para } i\neq j \text{ con } 1\le i,j\le k \text{ y } \langle \vec{n}_i , \vec{n}_i \rangle=1 \text{ para } 1\le i\le k.
\]
por lo que podemos caracterizar a un conjunto ortonormal como sigue:
\[
    \text{N}=\{\vec{n}_1,...,\vec{n}_k\}\subseteq V \ \text{es \emph{ortonormal} si} \ \langle \vec{n}_i , \vec{n}_j \rangle = \begin{cases} 1 &\text{si } j=i, \\ 0 &\text{si } j\neq i. \end{cases}
\]

En particular, si una base cumple con ser un conjunto ortonormal, decimos que es una \emph{base ortonormal}. Dado que se puede demostrar que todo conjunto ortonormal finito es linealmente independiente\footnote{Escribir ``*Ver Ejercicio 2.2.'' como nota al pie.}, tenemos que un conjunto $N$ es una base ortonormal de $V$ si se cumplen las condiciones siguientes\footnote{Escribir ``*Ver Ejercicio 2.3.''.}. 
\begin{align*}
    N=\{\vec{n}_1,...,\vec{n}_k\} \text{ es una base \emph{ortonormal} de } V \text{ si}& & &\\
    \langle N \rangle = V, \quad \langle \vec{n}_i , \vec{n}_j \rangle = \begin{cases} 1 &\text{si } j=i, \\ 0 &\text{si } j\neq i. \end{cases}
\end{align*}
Este tipo de bases son de gran utilidad, como veremos a continuación.

\subsection{Solución del problema de encontrar coeficientes usando bases ortonormales}

Regresemos ahora al problema por el cual introdujimos la operación de producto escalar, y veamos cómo entra la norma en nuestra discusión: tenemos un espacio vectorial de dimensión finita y queremos encontrar los coeficientes necesarios para expresar a un vector no nulo arbitrario como combinación lineal de una base. En el video anterior vimos que, si suponemos que nuestro espacio tiene producto escalar y que existe una base ortogonal, entonces los coeficientes se obtienen de la siguiente manera. Ahora, si consideramos la norma inducida por este producto escalar y suponemos que existe una base \emph{ortonormal} entonces, dado que dicha base en particular es ortogonal, podemos aplicar el mismo resultado. Más aún, como ahora todos los vectores de la base son normales, el resultado anterior se simplifica de la siguiente manera. Es decir, obtenemos que el cálculo de los coeficientes buscados se efectúa simplemente a través de un producto escalar.

Por esto es que las bases ortonormales son tan útiles en espacios vectoriales con producto escalar. Algunos ejemplos de este tipo de bases incluyen las bases canónicas de $\mathbb{R}^2$ y $\mathbb{R}^3$. 

En el siguiente video, veremos cómo podemos obtener conjuntos ortogonales y ortonormales a partir de un conjunto linealmente independiente. Como consecuencia de esto, veremos además que las bases ortogonales y ortonormales siempre existen en espacios vectoriales de dimensión finita con producto escalar, lo que justifica \emph{a posteriori} toda la discusión contenida en este video y en el video previo.

%%%%%%%%%%%%%%%%%%%%%%%%%% ÚLTIMA ESCENA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Ejercicios y preguntas}

%\begin{center}
%    Sea $V$ un espacio vectorial con producto escalar.
%\end{center}

Ejercicio 2.1 Sea $V$ un espacio vectorial con norma $||\cdot||:V\to \mathbb{R}_{\geq0}$. Para $\vec{u}\in V$, demuestra que \[
    \vec{u} \neq \vec{0} \implies ||\vec{u}|| > 0,
\] 
es decir, que la norma es una operación positivo definida. Adicionalmente, demuestra que la implicación contraria también se verifica. \\

%Ejercicio 2.2 Una \emph{métrica} o \emph{función de distancia} en un conjunto $X$ es una función $d(\cdot, \cdot ):X\times X\to \mathbb{R}_{\geq0}$ que cumple las siguientes propiedades:
%\begin{enumerate}[label=(\roman*)]
%    \item $d(x,y)=0$ si, y sólo si, $x=y$;
%
%    \item $d(x,y)=d(y,x)$ para cualesquiera $x,y\in X$;
%
%    \item $d(x,y) \le d(x,z) + d(z,y)$ para cualesquiera $x,y,z\in X$.
%\end{enumerate}
%
%\noindent Demuestra que la función $d(\cdot, \cdot ):X\times X\to \mathbb{R}_{\geq0}$ dada por $d(\vec{u},\vec{v})=||\vec{u}-\vec{v}||$ para todo $\vec{u},\vec{v}\in V$ es una métrica en $V$. Por ende, toda norma \emph{induce} una métrica y, en particular, todo producto escalar positivo definido induce una métrica; sin embargo, existen métricas que no son inducidas por normas ni productos escalares. \\

Ejercicio 2.2 Demuestra que todo conjunto ortonormal finito es linealmente independiente. \\

\begin{center}
    Sea $(V,K)$ un espacio vectorial con producto escalar $\langle \cdot , \cdot \rangle:V\times V\to K$ y norma inducida.

    Sean $\text{dim}(V)<\infty$ y $N=\{\hat{n}_1, \hat{n}_2, \dots, \hat{n}_k\}\subseteq V$.
\end{center}

Ejercicio 2.3 Demuestra que las siguientes condiciones son equivalentes.
\begin{enumerate}[label=(\alph*)]

    \item $N$ es una base ortonormal de $V$.

    \item $\langle N \rangle = V$ y $ \langle \vec{n}_i , \vec{n}_j \rangle = \begin{cases} 1 &\text{si } j=i, \\ 0 &\text{si } j\neq i. \end{cases}$
\end{enumerate}

Ejercicio 2.4 Demuestra que $N=\{\hat{n}_1,...,\hat{n}_k\}$ es una base \emph{ortonormal} de $V$ si, y sólo si,
\[
    \vec{v} = \sum_{i=1}^k \langle \vec{v} , \hat{n}_i \rangle \hat{n}_i \quad \forall \ \vec{v}\in V.
\]
Más aún, demuestra que, en este caso,
\[
    \big \langle \langle \vec{v} , \hat{n}_i \rangle \hat{n}_i, \langle \vec{v} , \vec{n}_j \rangle \vec{n}_j \big \rangle = 0 \ \ \text{si} \ \ i\neq j.
\] 

Pregunta 2.? ESCALABILIDAD ABSOLUTA CON ESCALARES DE VALOR ABSOLUTO UNO EN ESPACIOS REALES Y COMPLEJOS.

\end{document}
